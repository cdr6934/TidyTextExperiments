{
    "collab_server" : "",
    "contents" : "---\ntitle: \"tidyText and the Good Charles Dickens\"\noutput: html_notebook\n---\n\nhttps://github.com/ropensci/tokenizers/blob/master/vignettes/introduction-to-tokenizers.Rmd\nhttps://briatte.github.io/ggnet/\nhttp://rstats-db.github.io/DBI/\n\n\n```{r}\nlibrary(gutenbergr)\nlibrary(tidytext)\nlibrary(dplyr)\nlibrary(ggplot2)\n```\n\n\nYou can do this the hard way and go to the site and collect the books you want or... \n```{r}\n\n\nif(file.exists(\"dickensBooks.RData\"))\n{\n dickensBooks <-  load(\"dickensBooks.RData\")\n}\nif(!file.exists(\"dickensBooks.RData\")){\n  dickensBooks <- gutenberg_download(c(675,25985,917,676,1023,37121,42232,699,653,20795,766,1415,821,810,1422,1400,786,644,98,580,730,883,809,1394,2324,807,927,888,963,15618,23344,968,588,1407,700,1423,967,564,27924,912),meta_fields = c(\"title\",\"author\",\"language\")\n)\n  save(dickensBooks, file=\"dickensBooks.RData\")\n}\n\n```\nYou can read the documentation and pull the gutenberg ids like so...\n```{r}\ncharles <- gutenberg_works(author == \"Dickens, Charles\")\n```\n\n```{r}\n dickensBooks <-  load(\"dickensBooks.RData\")\ndickensBooks\n```\n\n\nNow what do you want to do with the books; generally we want to pull stop words within the corpus \n```{r}\ndickensBooks$text <- stri_enc_toutf8(dickensBooks$text,is_unknown_8bit = TRUE, validate = TRUE )\ntidy_dickens <- dickensBooks %>% unnest_tokens(word, text) %>% anti_join(stop_words)\ntidy_dickens\n```\nYou can also break it out more so that you have a better understanding of the placement of the word within the book. \n\n\n\n### Greater Than 3000 instances of words \n```{r}\ntidy_dickens %>%\n  count(word, sort = TRUE) %>%\n  filter(n > 3000) %>%\n  mutate(word = reorder(word, n)) %>%\n  ggplot(aes(word,n)) + \n  geom_bar(stat = \"identity\") + \n  xlab(NULL) +\n  coord_flip() + \n  ggtitle(\"Charles Dickens: 3000 Word occurences or more\")\n```\n\n\n```{r}\nlibrary(scales)\nggplot(frequency, aes(x = other, y = austen, color = abs(austen - other))) +\n  geom_abline(color = \"gray40\", lty = 2) +\n  geom_jitter(alpha = 0.1, size = 2.5, width = 0.3, height = 0.3) +\n  geom_text(aes(label = word), check_overlap = TRUE, vjust = 1.5) +\n  scale_x_log10(labels = percent_format()) +\n  scale_y_log10(labels = percent_format()) +\n  scale_color_gradient(limits = c(0, 0.001), low = \"darkslategray4\", high = \"gray75\") +\n  facet_wrap(~author, ncol = 2) +\n  theme(legend.position=\"none\") +\n  labs(y = \"Jane Austen\", x = NULL)\n```\n\n\n\n## Story Arches within the Text \n\n\n\nFollowing are all of the neames that are currently being used in the analysis of the data. Of course this is not as important to know. The gist of it all is to be able to take a large sum of data and understanding it better through multiple \n###Charles Dickens Analysis \nAmerican Notes 675\nBardell v Pickwick 25985\nBarnaby Rudge: A Tale of the Riots of 'Eighty 917\nThe Battle of Life 676\nBleak House 1023\nCharles Dickens' Children Stories 37121\nA Child's Dream of a Star 42232\nA Child's History of England 699\nThe Chimes 653\nThe Cricket on the Hearth 20795\nDavid Copperfield 766\nDoctor Marigold 1415\nDombey and Son 821\nGeorge Silverman's Explanation 810\nGoing into Society 1422\nGreat Expectations 1400\nHard Times 786\nThe Haunted Man and the Ghost's Bargain 644\nA Tale of Two Cities 98\nThe Pickwick Papers 580\nOliver Twist 730\nOur Mutual Friend 883\nHoliday Romance 809 \nThe Holly-Tree 1394\nA House to Let 2324\nHunted Down: The Detective Stories 807\nThe Lamplighter 927\nThe Lazy Tour of Two Idle Apprentice 888\nLittle Dorrit  963\nThe Loving Ballad of Lord Bateman 15618\nThe Magic Fishbone 23344\nMartin Chuzzlewit 968\nMaster Humphrey's Clock 588\nA Message from the Sea 1407\nThe Old Curiosity Shop 700\nNo Thoroughfare 1423\nNicholas Nickleby 967\nThe Mystery of Edwin Drood 564\nMugby Junction 27924\nMudfog and Other Sketches  912\nMrs. Lirriper's Lodgings 1416\nMiscellaneous Papers 1435\n",
    "created" : 1487825967752.000,
    "dirty" : true,
    "encoding" : "",
    "folds" : "",
    "hash" : "1917362561",
    "id" : "26B194D9",
    "lastKnownWriteTime" : 4321550080,
    "last_content_update" : 1488668369582,
    "path" : null,
    "project_path" : null,
    "properties" : {
        "chunk_output_type" : "inline",
        "tempName" : "Untitled4"
    },
    "relative_order" : 7,
    "source_on_save" : false,
    "source_window" : "",
    "type" : "r_markdown"
}